{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Fraud Detection in Bank Transaztions\"\n",
    "author: \"Darwhin Gomez\"\n",
    "date: \"`r Sys.Date()`\"  #\n",
    "output:\n",
    "  pdf_document:\n",
    "    toc: true\n",
    "    toc_depth: 4\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal: Fraud Detection in Bank Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Research Question**\n",
    "- **Null Hypothesis (H₀):**  \n",
    "  *\"Anomaly detection techniques, specifically clustering and isolation-based models, do not significantly identify outliers in transaction data that correspond to fraudulent activities.\"*\n",
    "\n",
    "- **Alternative Hypothesis (H₁):**  \n",
    "  *\"Anomaly detection techniques, specifically clustering and isolation-based models, can effectively identify outliers in transaction data that correspond to fraudulent activities.\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Justification**\n",
    "Fraud detection remains a critical challenge in the financial industry. As fraudulent activities can involve abnormal transaction behaviors, detecting outliers or anomalies in large transaction datasets is key to identifying potential fraud. This project uses unsupervised learning techniques such as **clustering** and **anomaly detection** to flag suspicious transactions based on transaction data. Since the dataset does not contain labeled fraud data, the task is framed as an **unsupervised anomaly detection** problem where outliers are presumed to represent fraudulent transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. **Data Source**\n",
    "https://www.kaggle.com/datasets/valakhorasani/bank-transaction-dataset-for-fraud-detection/data\n",
    "\n",
    "The dataset, **bank_transaction_data_2.csv**, contains transaction records for multiple customer accounts. The dataset includes the following features:\n",
    "\n",
    "- **TransactionID**: Unique alphanumeric identifier for each transaction.\n",
    "- **AccountID**: Unique identifier for each account, with multiple transactions per account.\n",
    "- **TransactionAmount**: Monetary value of each transaction.\n",
    "- **TransactionDate**: Timestamp of each transaction.\n",
    "- **TransactionType**: Categorical field indicating 'Credit' or 'Debit' transactions.\n",
    "- **Location**: Geographic location of the transaction, represented by U.S. city names.\n",
    "- **DeviceID**: Alphanumeric identifier for devices used to perform the transaction.\n",
    "- **IP Address**: IPv4 address associated with the transaction.\n",
    "- **MerchantID**: Unique identifier for merchants.\n",
    "- **AccountBalance**: Balance in the account post-transaction.\n",
    "- **PreviousTransactionDate**: Timestamp of the last transaction for the account.\n",
    "- **Channel**: Channel through which the transaction was performed (e.g., Online, ATM, Branch).\n",
    "- **CustomerAge**: Age of the account holder.\n",
    "- **CustomerOccupation**: Occupation of the account holder (e.g., Doctor, Engineer, Student, Retired).\n",
    "- **TransactionDuration**: Duration of the transaction in seconds.\n",
    "- **LoginAttempts**: Number of login attempts before the transaction, with higher values indicating potential anomalies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. **Tools and Libraries**\n",
    "- **Pandas**: For data manipulation and cleaning.\n",
    "- **NumPy**: For numerical operations.\n",
    "- **Matplotlib** and **Seaborn**: For data visualization (distributions, scatter plots, box plots, etc.).\n",
    "- **Scikit-Learn**:\n",
    "  - **Isolation Forest**: For unsupervised anomaly detection.\n",
    "  - **DBSCAN**: For density-based clustering and outlier detection.\n",
    "  - **KMeans**: For clustering and identifying potential fraud patterns.\n",
    "  - **StandardScaler**: For feature scaling and normalization.\n",
    "- **Datetime**: For handling and extracting features from the `TransactionDate` and `PreviousTransactionDate` columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. **Proposed Methodology**\n",
    "\n",
    "### **Data Preprocessing**\n",
    "- **Handle missing values**: Ensure no missing values are present (if any, apply appropriate imputation or removal).\n",
    "- **Categorical feature encoding**: Convert categorical variables (e.g., `TransactionType`, `Location`, `Channel`) into numerical values via **One-Hot Encoding** or **Label Encoding**.\n",
    "- **Datetime feature extraction**: Convert `TransactionDate` and `PreviousTransactionDate` into `datetime` format, and extract useful features such as the transaction hour, day, and time difference between consecutive transactions.\n",
    "- **Standardize numerical features**: Normalize or standardize continuous variables like `TransactionAmount`, `AccountBalance`, and `TransactionDuration` to ensure consistency across the models.\n",
    "\n",
    "### **Exploratory Data Analysis (EDA)**\n",
    "- **Univariate analysis**: Visualize distributions for features like `TransactionAmount`, `CustomerAge`, `AccountBalance`, and `TransactionType`.\n",
    "- **Bivariate analysis**: Investigate relationships between transaction features and account-level variables, such as how `TransactionAmount` varies with `CustomerAge`, `TransactionType`, or `AccountBalance`.\n",
    "- **Class distribution**: Although the dataset lacks a direct fraud flag, examining the distribution of certain features, such as `TransactionAmount` and `LoginAttempts`, can provide insights into potential fraud patterns.\n",
    "- **Outlier detection**: Visualize features such as `TransactionAmount` and `TransactionDuration` to identify outliers that might represent suspicious activity.\n",
    "\n",
    "### **Modeling**\n",
    "- **Isolation Forest**: Use the **Isolation Forest** algorithm, an unsupervised anomaly detection method, to identify transactions that differ significantly from the majority of data points. These outliers are likely to represent potential fraudulent transactions.\n",
    "- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: Cluster the data using DBSCAN, identifying dense regions of transactions. Points not assigned to any cluster are treated as \"noise\" (potential fraud).\n",
    "- **KMeans Clustering**: Apply **KMeans** to segment transactions into groups based on similar behavior, and flag transactions that don't belong well to any cluster.\n",
    "\n",
    "### **Evaluation**\n",
    "- **Fraud flagging**: Based on the output of the models, transactions that are flagged as outliers or noise will be considered as potential fraud.\n",
    "- **Visual inspection**: Visualize flagged anomalies on scatter plots and boxplots to validate if they align with typical fraud characteristics (e.g., large transaction amounts, multiple login attempts, etc.).\n",
    "- **Transaction patterns**: Assess the patterns of flagged transactions, such as unusual amounts or rapid transaction frequency, to evaluate the model's effectiveness in identifying suspicious behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd  # For data manipulation and cleaning (loading data, filtering, etc.)\n",
    "import numpy as np   # For numerical operations (e.g., mathematical calculations, arrays)\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt  # For basic plotting (e.g., histograms, scatter plots)\n",
    "import seaborn as sns          # For advanced statistical plots and better aesthetics\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.ensemble import IsolationForest  # For anomaly detection (Isolation Forest)\n",
    "from sklearn.cluster import DBSCAN           # For density-based clustering (DBSCAN)\n",
    "from sklearn.cluster import KMeans           # For KMeans clustering\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing features (important for clustering and anomaly detection)\n",
    "\n",
    "# For working with dates and times\n",
    "import datetime  # For handling and manipulating datetime objects (e.g., converting transaction date columns)\n",
    "\n",
    "# For handling warnings (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore warnings during model training (can be helpful for large datasets)\n",
    "\n",
    "# Load the dataset with a meaningful variable name\n",
    "bank_trans_data = pd.read_csv(\"bank_transactions_data_2.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Dataset Preview:\")\n",
    "print(bank_trans_data.head())\n",
    "\n",
    "\n",
    "# Check the basic info to understand data types and identify any missing values\n",
    "print(\"\\nDataset Information:\")\n",
    "print(bank_trans_data.info())\n",
    "\n",
    "\n",
    "# Display summary statistics to get an overview of the data distributions\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(bank_trans_data.describe())\n",
    "\n",
    "\n",
    "\n",
    "# Check for any missing values in the dataset\n",
    "missing_values = bank_trans_data.isnull().sum()\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "\n",
    "unique_counts = bank_trans_data.nunique()\n",
    "print(\"Unique Counts for Each Column:\")\n",
    "print(unique_counts)\n",
    "# Check the data types of all columns\n",
    "print(bank_trans_data.dtypes)\n",
    "\n",
    "# Define columns to exclude from categorical analysis\n",
    "excluded_cols = ['IP Address','TransactionID', 'AccountID', 'MerchantID', 'TransactionDate', 'DeviceID', 'PreviousTransactionDate']\n",
    "\n",
    "# Select categorical columns, excluding the identifier-like columns\n",
    "categorical_cols = bank_trans_data.select_dtypes(include=['object']).columns.difference(excluded_cols)\n",
    "\n",
    "# Display value counts for each remaining categorical column\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nValue Counts for {col}:\")\n",
    "    print(bank_trans_data[col].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# Initial Visualization of Transaction Amount Distribution\n",
    "sns.histplot(bank_trans_data['TransactionAmount'], kde=True)\n",
    "plt.title('Transaction Amount Distribution')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Boxplot to detect outliers in Transaction Amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=bank_trans_data['TransactionAmount'], color='orange')\n",
    "plt.title('Boxplot of Transaction Amount')\n",
    "plt.xlabel('Transaction Amount')\n",
    "plt.show()\n",
    "#  **Account Balance**\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(bank_trans_data['AccountBalance'], kde=True, color='red', bins=50)\n",
    "plt.title('Account Balance Distribution')\n",
    "plt.xlabel('Account Balance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Boxplot for Account Balance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=bank_trans_data['AccountBalance'], color='cyan')\n",
    "plt.title('Boxplot of Account Balance')\n",
    "plt.xlabel('Account Balance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 5. **Login Attempts**\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(bank_trans_data['LoginAttempts'], kde=True, color='brown', bins=30)\n",
    "plt.title('Login Attempts Distribution')\n",
    "plt.xlabel('Login Attempts')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for Login Attempts\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=bank_trans_data['LoginAttempts'], color='pink')\n",
    "plt.title('Boxplot of Login Attempts')\n",
    "plt.xlabel('Login Attempts')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6. **Transaction Duration**\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(bank_trans_data['TransactionDuration'], kde=True, color='teal', bins=30)\n",
    "plt.title('Transaction Duration Distribution')\n",
    "plt.xlabel('Transaction Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Boxplot for Transaction Duration\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=bank_trans_data['TransactionDuration'], color='grey')\n",
    "plt.title('Boxplot of Transaction Duration')\n",
    "plt.xlabel('Transaction Duration (seconds)')\n",
    "plt.show()\n",
    "# 3. **Customer Age**\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(bank_trans_data['CustomerAge'], kde=True, color='green', bins=30)\n",
    "plt.title('Customer Age Distribution')\n",
    "plt.xlabel('Customer Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Boxplot for Customer Age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=bank_trans_data['CustomerAge'], color='purple')\n",
    "plt.title('Boxplot of Customer Age')\n",
    "plt.xlabel('Customer Age')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
